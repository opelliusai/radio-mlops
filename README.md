# RADIO-MLOps

Ce repository concerne le projet de Radiographie Pulmonaire dans le cadre de la formation MLOps de Datascientest

## Acc√®s rapide
- [Le projet](#le-projet)
- [Architecture applicative](#architecture-applicative)
- [Applications et services](#applications-et-services)
- [Arborescence du projet](https://github.com/opelliusai/test_readme/blob/main/README.md#arborescence-du-projet)
- [Instructions d'utilisation](#instructions)
---
## Le projet
**Contexte**

D√©but 2020, la propagation rapide du coronavirus (COVID-19) a entrav√© la capacit√© des syst√®mes de sant√© √† r√©aliser les diagnostics et tests requis dans les d√©lais impos√©s par la pand√©mie. Ainsi, une recherche active de solutions alternatives pour le d√©pistage a √©t√© initi√©e.
En raison des effets significatifs du COVID-19 sur les tissus pulmonaires, l'usage de l'imagerie par radiographie thoracique s'est av√©r√© incontournable pour le d√©pistage et le suivi de la maladie lors de la crise COVID

**Objectif du client en 2024**
- Disposer d'un outil de diagnostic tout en conservant un taux √©lev√© de d√©tection COVID, mais sans n√©gliger d'autres pathologies, en particulier la Pneumonie Virale
- Mettre √† disposition de l'outil aux internes pour √©tablir un premier diagnostic
- Mettre √† contribution les Radiologues r√©f√©rents pour la validation du diagnostic

L'outil est donc √† la fois de diagnostic mais aussi p√©dagogique

**Use Case utilisateurs m√©tier**

Les utilisateurs m√©tiers disposent d'une application web pour charger les images et obtenir un diagnostic.<br>
Ils peuvent √©galement contribuer √† la validation de diagnostics pour am√©liorer le mod√®le

![](/references/MLOps_Utilisateurs_metier_workflow.png)

**Use Case administrateurs et datascientists**

Les utilisateurs dits techniques disposent de plusieurs outils pour administrer et g√©rer l'application et les mod√®les
- Une interface de suivi des performances du mod√®le
- Des outils annexes pour la gestion des op√©rations: MLFlow, Airflow, Prometheus et Grafana

Ces outils sont propos√©s aux utilisateurs techniques pour g√©rer les diff√©rentes √©tapes d'un produit de Machine Learning
![](/references/MLOps_Administrateurs_workflow.png)

---
## Architecture applicative

![](/references/Archi_Docker.png)
Plusieurs conteneurs Dockers sont cr√©√©s pour le projet avec 3 groupement principaux:
- **APIs**: 3 APIs d√©velopp√©s avec FastAPI
- **FrontEnd principal**: 1 application web streamlit qui s'interface exclusivement avec les apis via un module utilitaire (utils_streamlit)
- **1 groupe d'applications annexes**:
  - **MLFlow** :  Gestion du cycle de vie des mod√®les
  - **Airflow** : Ordonnancement
  - **Prometheus** : Etat de service des APIs et leur syst√®me via node_exporter
  - **Grafana**: Possibilit√© de cr√©er des dashboard (actuellement connect√© uniquement √† Prometheus et son node_exporter)

**Gestion des donn√©es - Metadata et versioning:**

![](/references/Gestion_donnees.png)
3 types de donn√©es:
- **Donn√©es Kaggle**: Les donn√©es source initiales qui servent √† entrainer les premi√®res mod√®les
- **Donn√©es de Production**: Les donn√©es enrichies par les utilisateurs lors des demandes de diagnostic
- **Donn√©es de R√©f√©rence**: L'agr√©gation des donn√©es et qui sont effectivement utilis√©es pour entrainer les mod√®le

**O√π sont stock√©es les donn√©es**
- Historique des versions des donn√©es: *processed/dataset_logging*
- Donn√©es versionn√©es:
  - **kaggle**: *raw/kaggle_datasets*
  - **reference**: *processed/ref_datasets*
  - **prod**: *processed/prod_dataset*s.

**Ce qu'il faut retenir**
- Pour entrainer les mod√®les, seules les donn√©es de r√©f√©rence sont utilis√©es. Les donn√©es Kaggle et prod alimentent ces donn√©es apr√®s une mise √† jour par l'administrateur ou par un batch (non configur√© ici).
- Un √©quilibrage est r√©alis√© sur la base de la classe minimale. Dans ce cas, un fichier metadata contenant la liste des images r√©ellement utilis√©e du dataset de r√©f√©rence est cr√©√© et associ√© au nouveau mod√®le.
  R√©pertoire contenant les metadata: *data/processed/models_data/MLOps_Radio_Model-$version/RadioPulmonaire_REF-<version_data>_MLOps_Radio_Model-<version_model>_metadata*
  exemple : data/processed/models_data/MLOps_Radio_Model-$version/RadioPulmonaire_REF-1.0_MLOps_Radio_Model-2_metadata.csv
  Ce fichier est accessible dans les Artifacts du Run d'entrainement, en plus des informations du dataset complet

  #### Artefact (avec informations apr√®s √©quilibrage des donn√©es)
<img src="/references/exemple_artefact_run.png" alt="" width="400"/>

**Gestion des mod√®les - MLflow:**
Le cycle de vie des mod√®les est g√©r√© dans MLFlow:
- **Entrainement**: Les hyperparam√®tres et m√©triques sont enregistr√©s. Le versioning des mod√®les est √©galement g√©r√© avec MLFlow
- **D√©ploiement**: D√©claration d'un mod√®le en Production en mettant √† jour sa phase en 'Production' et celle du mod√®le courant en 'Archived'. Bas√© sur un script qui d√©tecte un tag 'deploy_tag' dont la valeur serait 'production_ready'
- **Pr√©diction**: Chargement du mod√®le de production (√©tant en phase 'Production')
- **R√©entrainement**: Ajout des informations du mod√®le initial dans les informations du run associ√© au nouveau mod√®le.
  
![](/references/Gestion_modeles.png)

#### 
---
## Applications et services

**APIs :**

3 APIs ont √©t√© construites avec FastAPI et un swagger est disponible pour plus d'informations sur les services propos√©s (/docs)
- **API User _src/api/user_api_**: Disponible sur le port 8081.<br>
Elle est utilis√©e par l'application web et permet √† l'utilisateur de : 
    -  Effectuer une demande de diagnostic.
    -  Faire un retour sur le diagnostic
    -  Contribuer √† la labellisation des donn√©es dont le diagnostic n'a pas √©t√© valid√© par les utilisateurs 

- **API Admin _src/api/admin_api**: Disponible sur le port 8082.<br>
Elle est utilis√©e par l'application web et permet aux administrateurs de : 
    -  Lancer un t√©l√©chargement du dataset kaggle
    -  Lancer la mise √† jour des donn√©es de r√©f√©rence avec des donn√©es KAGGLE ou de PRODUCTION
    -  Lancer l'entrainement d'un mod√®le
    -  Consulter les informations sur les mod√®les du projet et de pr√©parer un mod√®le candidat au d√©ploiement, ou de forcer son d√©ploiement imm√©diat (en cas d'urgence par exemple)
 
- **API Monitoring _src/api/monitoring_api_**: Disponible sur le port 8083.<br>
Elle est d√©di√©e aux action de monitoring :
    - Calcul des metriques de drift : Mod√®le et Data
    - R√©entrainement du mod√®le de production si besoin (en option)

**Application Frontend - Streamlit :**
1 application web Streamlit a √©t√© d√©velopp√©e pour les utilisateurs et les administrateurs, chacun ayant acc√®s √† des fonctionnalit√©s en fonction de son profil/r√¥le. L'administrateur a acc√®s aux fonctionnalit√©s des utilisateurs m√©tier en plus de ses fonctionnalit√©s.

**Applications annexes :**
Les applications suivantes sont mise √† disposition √† l'administrateur pour la gestion du cycle de vie du produit.

- **Airflow :** Disponible sur le port 8093
    - **Healthcheck**: V√©rification de l'√©tat des services
    - **Deploy_model**: D√©ploiement de mod√®le pr√™ts pour la production (Rappel : Tag 'deploy_flag' dont la valeur est 'production_ready')
    - **Data Drift**: Calcul des mesures pour la d√©tection d'un Data drift et r√©entrainement du mod√®le si c'est le cas
    - **Model Drift**: Calcul des mesures pour la d√©tection d'un Model drift et r√©entrainement du mod√®le si c'est le cas

- **Prometheus et Grafana :**
Des m√©triques sont envoy√©es par l'APIs et les node exporter install√©s dans leurs images docker.
L'administrateur a acc√®s √† Prometheus pour consulter ces m√©triques
Prometheus v√©rifie √©galement l'√©tat de services des 3 APIs
**Grafana** est connect√© √† **Prometheus** pour permettre √† l'administrateur de cr√©er ses Dashboards.
  
------------
## Applications et ports associ√©s

| Application   | Port   | 
|-------------|-------------|
| User API | 8081 | 
| Admin API | 8082 | 
| Monitoring API | 8083 | 
| MLFlow | 8090 | 
| Prometheus | 8091 | 
| Grafana | 8092 | 
| Airflow | 8093 | 
| Streamlit | 8084 | 

## Arborescence du projet

    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ README.md               <- README principal pour le projet
    ‚îú‚îÄ‚îÄ data                    <- R√©pertoire des donn√©es - local (dans .gitignore)
    ‚îÇ   ‚îú‚îÄ‚îÄ archives		<- Archivage 
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ models			<- Les mod√®les 	
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed	   	<- Les donn√©es apr√®s transformation 
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dataset_logging     <- Fichiers sur l'historique des versions (ref, kaggle, prod)
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ keras_tuner 	<- R√©pertoire d√©di√© aux rapports de Keras Random Search
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mlflow_runs 	<- R√©pertoire d√©di√© aux rapports g√©n√©r√©s lors de l'entrainement (history etc.)
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mlruns 		<- R√©pertoire utilis√© au d√©marrage de MLFlow (Runs et Artifacts)
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model_drift 	<- R√©pertoire d√©di√© aux model drifts
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data_drift 	        <- R√©pertoire d√©di√© aux data drifts
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models_data 	<- M√©tadata des donn√©es utilis√©s par les mod√®les apr√®s √©quilibrage des classes pour une version donn√©e de dataset de r√©f√©rence
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ predictions 	<- Fichiers de log des pr√©dictions
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prod_datasets 	<- Datasets de Production avec versions
    ‚îÇ   ‚îÇ   ‚îÇ   
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ref_datasets 	<- Datatsets de R√©f√©rence avec versions
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pytest_reports 	<- Rapports d'ex√©cution des tests unitaires
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ raw                	<- Les donn√©es brutes Kaggle 
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ kaggle_datasets  	<- Dataset Kaggle, t√©l√©charg√© et versionn√©
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prediction_images 	<- R√©pertoire de sauvegarde des images charg√©es par les utilisateurs (avant d'alimenter la base de donn√©es de production avec ou sans labellisation)
    ‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ streamlit_assets 	<- Images, graphiques pour Streamlit
    ‚îÇ   ‚îÇ¬†  ‚îî‚îÄ‚îÄ test_images		<- Images de tests (pour les tests unitaires, depuis l'API ou depuis Streamlit)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ     
    ‚îú‚îÄ‚îÄ docker-compose                   <- R√©pertoire des fichiers pour la construction des images et d√©marrage des container dockers
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ docker-compose.yml           <- Le fichier regroupant toutes les images Docker √† cr√©er
    ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose_<<nom_image>> <- Le fichier docker-compose d√©di√© √† chaque image
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ Dockerfile_<<nom_image>>    	<- Le fichier Dockerfile d√©di√© √† chaque image
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements                     <- R√©pertoire des fichiers requirements par image
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ requirements.txt	     <- Fichier des requirements principal
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ requirements_<<nom_image>>.txt <- Fichier des requirements par image, copi√© via le Dockerfile
    ‚îÇ
    ‚îú‚îÄ‚îÄ src                     <- Code source du projet
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ api                 <- APIs FastAPI
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ config              <- Fichiers de configuration des param√®tres et des logs
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ datasets            <- Fonctions de traitement des bases de donn√©es
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mlflow              <- Fonctions de tracking et de serving des mod√®les sur MLFlow
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models              <- Fonction de construction, d'entrainement du mod√®le et de pr√©diction
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ streamlit	    <- Application m√©tier Streamlit
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ streamlit_pres      <- Application projet Streamlit (Soutenance)
    ‚îÇ   ‚îÇ    
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ tests          	    <- Tests unitaires
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utils               <- Fonctions utiles 

---
## Instructions

Les instructions sont list√©es par type d'usage souhait√© par le d√©veloppeur
- [Utiliser les images Dockerhub](#-utilisation-des-images-docker-sur-dockerhub)
- [Construire les images et d√©marrer les conteneurs Docker](#-construire-les-images-et-d%C3%A9marrer-les-conteneurs-docker)
- [Lancer les applications localement (Maintenance du code)](#lancer-les-applications-localement-maintenance-du-code)
- [Exemple de mise en place d'un environnement de machine learning](#exemple-de-mise-en-place-dun-environnement-de-machine-learning-pour-le-projet)

‚ö†Ô∏è : Les instructions Docker supposent que les pr√©-requis sont maitris√©s:
- Installation de Docker sur son poste de d√©veloppement ou de serveur de d√©ploiement
- Compte Docker cr√©√© sur Dockerhub pour r√©cup√©rer les images

### üê≥ **Utilisation des images Docker sur Dockerhub**
**Repository de r√©f√©rence:** [https://hub.docker.com/repositories/opelliusai](https://hub.docker.com/repositories/opelliusai)

### 1. Liste des images disponibles
| Image   | URL   | 
|-------------|-------------|
| User API | opelliusai/user_api | 
| Admin API | opelliusai/admin_api | 
| Monitoring API | opelliusai/monitoring_api | 
| MLFlow | opelliusai/mlflow | 
| Prometheus | opelliusai/prometheus | 
| Grafana | opelliusai/grafana | 
| Streamlit | opelliusai/streamlit | 

#### 2. Utilisation
Un fichier docker-compose est mis √† disposition pour utiliser les derni√®res images disponibles sur dockerhub
**Localisation dans github**: docker-compose/docker-compose_using_dockerhub.yml

### üê≥ **Construire les images et d√©marrer les conteneurs Docker**
Le r√©pertoire _docker-compose_ contient trois outils pour la construction et lancement des images:
Se positionner dans le r√©pertoire docker-compose<br>
`cd docker-compose`

#### Construction et lancement de toutes les images avec docker-compose
En utilisant le fichier _docker-compose.yml_
**Construction**
`docker-compose build --no-cache`
**Lancement**
`docker-compose up -d`

#### Construction et lancement de toutes les images avec des scripts sh
**Construction**
`./docker-compose_all_build.sh`
**Lancement**
`./docker-compose_all_start.sh`

#### Construction et lancement image par image
En utilisant le fichier _docker-compose_<nom_image>.yml_
Exemple avec user_api
**Construction**
`docker-compose -f docker-compose_user_api.yml build --no-cache`
**Lancement**
`docker-compose -f docker-compose_user_api.yml up -d`

‚ö†Ô∏èCes deux types de constructions/d√©marrage n'incluent pas airflow qui doit √™tre d√©marr√© s√©par√©ment

### Installation Airflow
L'image Airflow n'est pas disponible sur dockerhub mais ses fichiers de lancement sont disponible sur github
**Localisation dans github**: docker-compose/docker-compose_airflow.yml
Plus d'informations sur airflow [ici](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)
le fichier _docker-compose_airflow.yml_ est configur√© pour utiliser le r√©pertoire _../airflow_ (√† la racine du projet github) comme base de travail de l'application Airflow 

#### 1. Renseigner les informations pour l'envoi des mails
Il faut √©galement renseigner les informations pour l'envoi des mails (voir la section environment: et les variables AIRFLOW__SMTP__SMTP_*
```text
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    AIRFLOW__SMTP__SMTP_HOST: your_host
    AIRFLOW__SMTP__SMTP_STARTTLS: True
    AIRFLOW__SMTP__SMTP_SSL: False
    AIRFLOW__SMTP__SMTP_USER: youremail@domain.com
    AIRFLOW__SMTP__SMTP_PASSWORD: your_password
    AIRFLOW__SMTP__SMTP_PORT: your_smtp_service_port
    AIRFLOW__SMTP__SMTP_MAIL_FROM: youremail@domain.com
    AIRFLOW__SMTP__SMTP_MAIL_TO: your_dest_email@domain.com
```
    
#### 2. Cr√©er les r√©pertoires et r√©cup√©rer AIRFLOW_ID pour l'environnement Airflow
```text
cd airflow
mkdir -p ./dags ./logs ./plugins ./config
echo -e "AIRFLOW_UID=$(id -u)" > .env
```
#### 3. Initialisation de l'environnement
```text
docker-compose -f docker-compose_airflow.yml up airflow-init
```
#### 4. D√©marrage d'Airflow
```text
docker-compose -f docker-compose_airflow.yml up -d
```

### Lancer les applications localement (Maintenance du code)

**Instructions:**

1. Mettre √† jour src/config/run_config.py
Les APIs lanc√©es localement ont des IPs 127.0.0.1 localhost
Par cons√©quent, remplacer le contenu de run_config.py >> LOCAL_run_config.py

2. Cr√©er un environnement virtuel<br>
```text
python3 -m venv radioEnv
```
3. Activer l‚Äôenvironnement<br>
```text
source radioEnv/bin/activate
```
4. Ajouter le projet dans la variable PYTHONPATH<br>

5. Installer les pr√©-requis<br>
```text
pip install -r requirements.txt
```

6. Cr√©er tous les r√©pertoires n√©cessaires<br>
Ce module permet de cr√©er tous les r√©pertoires n√©cessaires pour le projet (qui ne sont pas dans le repository github
Voir structure du projet pour plus d'information
Techniquement, ce script se base sur le dictionnaire init_paths du fichier `src/config/run_config.py` pour cr√©er les r√©pertoire
Il est √©galement int√©gr√© √† toutes les images Docker pour s'assurer que l'arborescence est cr√©√©e.

```text
python src/utils/utils_folders_init.py
```

7. Ex√©cution locale des d√©veloppements (API) <br>
**Depuis la racine du projet github **
| Image   | Commande   | 
|-------------|-------------|
| User API | `python src/api/user_api.py` | 
| Admin API | `python src/api/admin_api.py` | 
| Monitoring API | `python src/api/monitoring_api` | 

### Exemple de mise en place d'un environnement de Machine Learning pour le projet<br>
1. T√©l√©chargement des donn√©es
- API Admin / Endpoint **/download_dataset**
- Les donn√©es seront stock√©es dans le volume docker-compose_shared-data
chemin data/raw/kaggle_dataset/
et versionn√©es sous le format COVID-19_Radiography_Dataset-X.Y (X.Y √©tant la derni√®re version mineure)
- Le log de t√©l√©chargement seront stock√©s dans 
data/processed/dataset_logging/kaggle_dataset_logging.csv

2. Construction des donn√©es de r√©f√©rence
-- API Admin / Endpoint **/update_dataset**
source_type="KAGGLE"
- Les donn√©es seront stock√©es dans le volume *docker-compose_shared-data*
chemin: data/processed/ref_dataset/
et versionn√©es sous le format  RadioPulmonaire-X.Y (X.Y √©tant la derni√®re version par incr√©mentation mineure (ex : 1.0 > 1.1)
- Le log de t√©l√©chargement seront stock√©s dans 
data/processed/dataset_logging/ref_dataset_logging.csv

3. Entrainement de mod√®les
-- API Admin ou Streamlit Page Entrainement/Reentrainement de modele
Entrainement initiale : 
-- API: Options par d√©faut
-- Streamlit:
Option "Entrainement complet (Donn√©es de r√©f√©rence uniquement)
- S√©lection du Dataset
- Hyperparam√®tre: Max Epochs / Num trials

4. D√©ploiement d'un mod√®le initial
-- Streamlit : Information et d√©ploiement de mod√®les
  - D√©ploiement imm√©diat: Bouton "Forcer le d√©ploiement"
  - D√©ploiement par batch airflow: Bouton "Pr√©parer pour le d√©ploiement"

5. Pr√©diction 
-- Streamlit: Connexion utilisateur

### Annexe 1 - Github - Gestion des secrets<br>

| Variable secret   | Utilit√©  | 
|-------------|-------------|
| DOCKER_TOKEN | Dockerhub | 
| DOCKER_USERNAME |  Dockerhub | 
| JWT_SECRET_KEY | Les APIs | 
| KAGGLE_JSON | Admin API | 
| MONITORING_API_KEY | Monitoring API | 
| USERS_JSON | Les APIs | 
| USER_API_KEY | User API | 

### Annexe 2 - Format streamlit_users.json / Variable secret USERS_JSON<br>
{
    "cle_user1": {"username": "identifiant1", "password": "mot_de_passe1", "user_name":"nom_prenom","role": "user"},
    "cle_user2": {"username": "identifiant2", "password": "mot_de_passe2", "user_name":"nom_prenom","role": "admin"},
    ...
}

### Annexe 3 - Github Actions - Workflows<br>
1 workflow par image docker **Docker Build <nom_image>**
1 workflow pour la construction et le push de toutes les images: **Docker Build all containers**

[Retour au menu principal](#acc%C3%A8s-rapide)
[Retour aux instructions](#instructions)

--------
<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
